{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ab7498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import urllib\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ab2c0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'aircraft carrier', b'airplane', b'alarm clock', b'ambulance', b'angel', b'animal migration', b'ant', b'anvil', b'apple', b'arm']\n"
     ]
    }
   ],
   "source": [
    "categories = [line.rstrip(b'\\n') for line in urllib.request.urlopen('https://raw.githubusercontent.com/googlecreativelab/quickdraw-dataset/master/categories.txt')]\n",
    "print(categories[:10])\n",
    "category = 'candle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebb156f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141545 images to train on\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir('npy_files'):\n",
    "    os.mkdir('npy_files')\n",
    "    \n",
    "url = f'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/{category}.npy'  \n",
    "urllib.request.urlretrieve(url, f'npy_files/{category}.npy')\n",
    "\n",
    "train_images = np.load(f'npy_files/{category}.npy')\n",
    "print(f'{len(train_images)} images to train on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06aebfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 255\n"
     ]
    }
   ],
   "source": [
    "print(np.min(train_images), np.max(train_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d035e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "\n",
    "def preprocess(data):\n",
    "    # DATA TYPE\n",
    "    data = data.map(lambda img: (tf.cast(img, tf.float32)))\n",
    "    # NORMALIZE\n",
    "    data = data.map(lambda img: (img/255.))\n",
    "    # DUPING AND NOISE\n",
    "    data = data.map(lambda img: (tf.reshape(img, (28, 28, 1))))\n",
    "    # DATAFLOW PREP\n",
    "    data = data.cache()\n",
    "    data = data.shuffle(1000, seed=42)\n",
    "    data = data.batch(32)\n",
    "    data = data.prefetch(3)\n",
    "    return data\n",
    "\n",
    "dataset = dataset.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa1d2c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 17:58:42.226783: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = next(iter(dataset))\n",
    "\n",
    "x = tf.concat([x[i, ...] for i in range(4)], axis=1)\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.imshow(x, cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff8c41c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "class Model(tf.keras.Model):\n",
    "    NAME = 'NAMELESS_MODEL'\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.is_setup = False\n",
    "        self.loss_metric = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        self.prev_epochs = 0\n",
    "    \n",
    "    \n",
    "    def reset_metrics(self):\n",
    "        for metric in self.metrics:\n",
    "            metric.reset_state()\n",
    "    \n",
    "    \n",
    "    def setup(self):\n",
    "        if self.is_setup:\n",
    "            return\n",
    "        # DEFINE PATHSf\n",
    "        current_time = datetime.datetime.now().strftime(\"%Y.%m.%d-%H:%M:%S\")\n",
    "        train_log_path = f\"logs/{self.NAME}{current_time}/train\"\n",
    "        val_log_path = f\"logs/{self.NAME}{current_time}/val\"\n",
    "        # CONSTRUCT WRITERS\n",
    "        self.writer_train = tf.summary.create_file_writer(train_log_path)\n",
    "        self.writer_val   = tf.summary.create_file_writer(val_log_path)\n",
    "        self.is_setup = True\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, x, training=False):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, training=training)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def step(self, X, training=True):\n",
    "        if training:\n",
    "            with tf.GradientTape() as tape:\n",
    "                L = self.loss(X)\n",
    "            gradient = tape.gradient(L, self.trainable_weights)\n",
    "            self.optimizer.apply_gradients(zip(gradient, self.trainable_weights))\n",
    "        else:\n",
    "            L = self.loss(X)\n",
    "        self.loss_metric.update_state(L)\n",
    "        return {metric.name: float(metric.result()) for metric in self.metrics}\n",
    "\n",
    "\n",
    "    def train(self, train, epochs):\n",
    "        training_metrics = {metric.name: [] for metric in self.metrics}\n",
    "        testing_metrics = {metric.name: [] for metric in self.metrics}\n",
    "        self.setup()\n",
    "        with tqdm(epochs) as bar:\n",
    "            bar.set_description('TRAINING')\n",
    "            for epoch in range(epochs):\n",
    "                # TRAINING\n",
    "                for X in train:\n",
    "                    metrics = self.step(X, training=True)\n",
    "                    for name, value in metrics.items():\n",
    "                        training_metrics[name].append(value)\n",
    "                # WRITING METRICS\n",
    "                with self.writer_train.as_default():\n",
    "                    for metric in self.metrics:\n",
    "                        tf.summary.scalar(metric.name, metric.result(), step=self.prev_epochs)\n",
    "                self.reset_metrics()\n",
    "                bar.update(1)\n",
    "                self.prev_epochs += 1\n",
    "            metrics = {metric.name: [training_metrics[metric.name], testing_metrics[metric.name]] for metric in self.metrics}\n",
    "            return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3fb16834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[0.52494144],\n",
       "       [0.4750586 ]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dense = tf.keras.layers.Dense(9 * 256, activation='relu')\n",
    "        self.flatten = tf.keras.layers.Reshape((3, 3, 256))\n",
    "        self.conv_0 = tf.keras.layers.Conv2DTranspose(filters=256, kernel_size=(3, 3), strides=(2, 2), padding='valid', activation='relu')\n",
    "        # (7, 7, 256)\n",
    "        self.conv_1 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu')\n",
    "        self.conv_2 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu')\n",
    "        self.norm_0 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv_3 = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=(3, 3), strides=(2, 2), padding='same', activation='relu')\n",
    "        # (14, 14, 128)\n",
    "        self.conv_4 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu')\n",
    "        self.conv_5 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu')\n",
    "        self.norm_1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv_6 = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), strides=(2, 2), padding='same', activation='relu')\n",
    "        # (28, 28, 128)\n",
    "        self.conv_7 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')\n",
    "        self.conv_8 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')\n",
    "        self.norm_2 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv_9 = tf.keras.layers.Conv2D(filters=1, kernel_size=(3, 3), padding='same')\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        \n",
    "        \n",
    "    def call(self, batch_size, training=True):\n",
    "        X = tf.random.normal((batch_size, 256))\n",
    "        X = self.dense(X, training=training)\n",
    "        X = self.flatten(X, training=training)\n",
    "        X = self.conv_0(X, training=training)\n",
    "        # 1st BLOCK\n",
    "        Z = self.conv_1(X, training=training)\n",
    "        Z = self.conv_2(Z, training=training)\n",
    "        Z = Z + X\n",
    "        self.norm_0(Z, training=training)\n",
    "        X = self.conv_3(Z, training=training)\n",
    "        # 2nd BLOCK\n",
    "        Z = self.conv_4(X, training=training)\n",
    "        Z = self.conv_5(Z, training=training)\n",
    "        Z = Z + X\n",
    "        self.norm_1(Z, training=training)\n",
    "        X = self.conv_6(Z, training=training)\n",
    "        # 3rd BLOCK\n",
    "        Z = self.conv_7(X, training=training)\n",
    "        Z = self.conv_8(Z, training=training)\n",
    "        Z = Z + X\n",
    "        self.norm_2(Z, training=training)\n",
    "        X = self.conv_9(Z, training=training)\n",
    "        return X\n",
    "        \n",
    "\n",
    "\n",
    "class Discriminator(tf.keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv_0 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')\n",
    "        # (28, 28, 64)\n",
    "        self.conv_1 = tf.keras.layers.SeparableConv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')\n",
    "        self.conv_2 = tf.keras.layers.SeparableConv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')\n",
    "        self.norm_0 = tf.keras.layers.BatchNormalization()\n",
    "        self.pool_0 = tf.keras.layers.AveragePooling2D(pool_size=(2, 2))\n",
    "        # (14, 14, 128)\n",
    "        self.conv_3 = tf.keras.layers.SeparableConv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')\n",
    "        self.conv_4 = tf.keras.layers.SeparableConv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')\n",
    "        self.norm_1 = tf.keras.layers.BatchNormalization()\n",
    "        self.pool_1 = tf.keras.layers.AveragePooling2D(pool_size=(2, 2))\n",
    "        # (7, 7, 256)\n",
    "        self.conv_5 = tf.keras.layers.SeparableConv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')\n",
    "        self.conv_6 = tf.keras.layers.SeparableConv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')\n",
    "        self.norm_2 = tf.keras.layers.BatchNormalization()\n",
    "        self.pool_2 = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        # (256)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "    \n",
    "    \n",
    "    def call(self, X, training=True):\n",
    "        # Constructing Filterspace\n",
    "        X = self.conv_0(X, training=training)\n",
    "        # 1st BLOCK\n",
    "        Z = self.conv_1(X, training=training)\n",
    "        Z = self.conv_2(Z, training=training)\n",
    "        Z = Z + tf.concat([X, X], axis=3)\n",
    "        Z = self.norm_0(Z, training=training)\n",
    "        X = self.pool_0(Z, training=training)\n",
    "        # 2nd BLOCK\n",
    "        Z = self.conv_3(X, training=training)\n",
    "        Z = self.conv_4(Z, training=training)\n",
    "        Z = Z + tf.concat([X, X], axis=3)\n",
    "        Z = self.norm_1(Z, training=training)\n",
    "        X = self.pool_1(Z, training=training)\n",
    "        # 3rd BLOCK\n",
    "        Z = self.conv_5(X, training=training)\n",
    "        Z = self.conv_6(Z, training=training)\n",
    "        Z = Z + tf.concat([X, X], axis=3)\n",
    "        Z = self.norm_2(Z, training=training)\n",
    "        X = self.pool_2(Z, training=training)\n",
    "        # FINALLY\n",
    "        X = self.flatten(X)\n",
    "        P = self.dense(X)\n",
    "        return P\n",
    "\n",
    "\n",
    "\n",
    "G = Generator()\n",
    "D = Discriminator()\n",
    "D(G(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3b60d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "class GAN(tf.keras.Model): # aka Adversarial Minmax\n",
    "    NAME = 'NAMELESS_MODEL'\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.G = Generator()\n",
    "        self.D = Discriminator()\n",
    "        self.is_setup = False\n",
    "        self.loss = tf.keras.losses.BinaryCrossentropy()\n",
    "        self.loss_metric = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        self.prev_epochs = 0\n",
    "    \n",
    "    \n",
    "    def reset_metrics(self):\n",
    "        for metric in self.metrics:\n",
    "            metric.reset_state()\n",
    "    \n",
    "    \n",
    "    def setup(self):\n",
    "        if self.is_setup:\n",
    "            return\n",
    "        # DEFINE PATHSf\n",
    "        current_time = datetime.datetime.now().strftime(\"%Y.%m.%d-%H:%M:%S\")\n",
    "        train_log_path = f\"logs/{self.NAME}{current_time}\"\n",
    "        # CONSTRUCT WRITERS\n",
    "        self.writer = tf.summary.create_file_writer(train_log_path)\n",
    "        self.is_setup = True\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, X_true, training=False):\n",
    "        batch_size = X_true.shape[0]\n",
    "        X_false = self.G(batch_size)\n",
    "        X = tf.concat([X_true, X_false], axis=0)\n",
    "        P = self.D(X)\n",
    "        return P\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def step(self, X_true, training=True):\n",
    "        batch_size = X_true.shape[0]\n",
    "        T = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\n",
    "        if training:\n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "                P = self(X_true, training=training)\n",
    "                L_D = self.loss(T, P)\n",
    "                L_G = -L_D\n",
    "            nabla_G = tape.gradient(L_G, self.G.trainable_weights)\n",
    "            nabla_D = tape.gradient(L_D, self.D.trainable_weights)\n",
    "            self.G.optimizer.apply_gradients(zip(nabla_G, self.G.trainable_weights))\n",
    "            self.D.optimizer.apply_gradients(zip(nabla_D, self.D.trainable_weights))\n",
    "        else:\n",
    "            P = self(X_true)\n",
    "            L_D = self.loss(T, P)\n",
    "        self.loss_metric.update_state(L_D)\n",
    "        return {metric.name: float(metric.result()) for metric in self.metrics}\n",
    "\n",
    "\n",
    "    def train(self, dataset, epochs):\n",
    "        training_metrics = {metric.name: [] for metric in self.metrics}\n",
    "        testing_metrics = {metric.name: [] for metric in self.metrics}\n",
    "        self.setup()\n",
    "        with tqdm(epochs) as bar:\n",
    "            bar.set_description('TRAINING')\n",
    "            for epoch in range(epochs):\n",
    "                # TRAINING\n",
    "                for X_true in dataset:\n",
    "                    metrics = self.step(X_true, training=True)\n",
    "                    for name, value in metrics.items():\n",
    "                        training_metrics[name].append(value)\n",
    "                # WRITING METRICS\n",
    "                with self.writer_train.as_default():\n",
    "                    for metric in self.metrics:\n",
    "                        tf.summary.scalar(metric.name, metric.result(), step=self.prev_epochs)\n",
    "                self.reset_metrics()\n",
    "                bar.update(1)\n",
    "                self.prev_epochs += 1\n",
    "            metrics = {metric.name: [training_metrics[metric.name], testing_metrics[metric.name]] for metric in self.metrics}\n",
    "            return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2bd474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING: : 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['generator_17/batch_normalization_81/gamma:0', 'generator_17/batch_normalization_81/beta:0', 'generator_17/batch_normalization_82/gamma:0', 'generator_17/batch_normalization_82/beta:0', 'generator_17/batch_normalization_83/gamma:0', 'generator_17/batch_normalization_83/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['generator_17/batch_normalization_81/gamma:0', 'generator_17/batch_normalization_81/beta:0', 'generator_17/batch_normalization_82/gamma:0', 'generator_17/batch_normalization_82/beta:0', 'generator_17/batch_normalization_83/gamma:0', 'generator_17/batch_normalization_83/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    }
   ],
   "source": [
    "model = GAN()\n",
    "model.train(dataset, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
