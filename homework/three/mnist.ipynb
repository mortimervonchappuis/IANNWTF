{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91955e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "(train, test) , info = tfds.load('mnist', split =['train', 'test'], \n",
    "                                 as_supervised=True , with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6fc779",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134de44b",
   "metadata": {},
   "source": [
    "1. How manny train/test images are there? — 60,000/10,000\n",
    "2. Whats the image shape? — (28, 28, 1)\n",
    "3. What rage are the pixel values in? — [0; 255]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4c8926",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfds.show_examples (train, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36ceaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    # RESHAPE\n",
    "    data = data.map(lambda img, target: (tf.reshape(img, (28**2,)), target))\n",
    "    # DATA TYPE\n",
    "    data = data.map(lambda img, target: (tf.cast(img, tf.float32), target))\n",
    "    # NORMALIZE\n",
    "    data = data.map(lambda img, target: (img/128. - 1., target))\n",
    "    # ONE HOT ENCODING\n",
    "    data = data.map(lambda img, target: (img, tf.one_hot(target, depth=10)))\n",
    "    # DATAFLOW PREP\n",
    "    data = data.cache()\n",
    "    data = data.shuffle(1000, seed=42)\n",
    "    data = data.batch(32)\n",
    "    data = data.prefetch(20)\n",
    "    return data\n",
    "\n",
    "train = train.apply(preprocess)\n",
    "test  = test.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb88381",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine(tf.keras.layers.Layer):\n",
    "    name = 'Affine'\n",
    "    def __init__(self, n_output, activation, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.n_output   = n_output\n",
    "        self.activation = activation if activation is not None else tf.identity\n",
    "    \n",
    "\n",
    "    def build(self, n_input):\n",
    "        self.n_input = n_input[-1]\n",
    "        limit = math.sqrt(6/(self.n_input + self.n_output))\n",
    "        self.W = tf.Variable(tf.random.uniform((self.n_input, self.n_output), -limit, limit))\n",
    "        self.b = tf.Variable(tf.zeros(shape=(1, self.n_output)))\n",
    "        \n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        return self.activation(x @ self.W + self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608b22ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vanilla(tf.keras.Model):\n",
    "    def __init__(self, sizes, activations, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.layers_list = [Affine(size, activation) for size, activation in zip(sizes, activations)]\n",
    "        self.optimizer = tf.keras.optimizers.Adam()\n",
    "        self.loss_metric = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        self.accuracy_metric = tf.keras.metrics.CategoricalAccuracy(name=\"acc\")\n",
    "        self.loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    \n",
    "    def reset_metrics(self):\n",
    "        for metric in self.metrics:\n",
    "            metric.reset_state()\n",
    "    \n",
    "        \n",
    "    def __iter__(self):\n",
    "        return iter(self.layers)\n",
    "\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        for layer in self:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, X, T):\n",
    "        # TRAIN NETWORK\n",
    "        with tf.GradientTape() as tape:\n",
    "            Y_logit = self(X)\n",
    "            L = self.loss(T, Y_logit)\n",
    "        gradient = tape.gradient(L, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradient, self.trainable_variables))\n",
    "        # UPDATE METRICS\n",
    "        Y = tf.nn.softmax(Y_logit)\n",
    "        self.loss_metric.update_state(L)\n",
    "        self.accuracy_metric.update_state(T, Y)\n",
    "        return {metric.name: float(metric.result()) for metric in self.metrics}\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def test_step(self, X, T):\n",
    "        # COMPUTE METRICS\n",
    "        Y_logit = self(X)\n",
    "        Y = tf.nn.softmax(Y_logit)\n",
    "        L = self.loss(T, Y_logit)\n",
    "        # UPDATE METRICS\n",
    "        self.loss_metric.update_state(L)\n",
    "        self.accuracy_metric.update_state(T, Y)\n",
    "        return {metric.name: metric.result() for metric in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74829fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Vanilla([128, 64, 32, 10], [tf.nn.relu, tf.nn.relu, tf.nn.relu, None])\n",
    "model(np.zeros((1, 28**2)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abb3d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "# DEFINE PATHS\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_path = f\"logs/{current_time}/train\"\n",
    "val_log_path = f\"logs/{current_time}/val\"\n",
    "\n",
    "# CONSTRUCT WRITERS\n",
    "writer_train = tf.summary.create_file_writer(train_log_path)\n",
    "writer_val   = tf.summary.create_file_writer(val_log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65d2d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def training(epochs, model, train, test):\n",
    "    with tqdm(range(epochs), leave=True) as out_bar:\n",
    "        for epoch in out_bar:\n",
    "            with tqdm(train, leave=False) as in_bar:\n",
    "                out_bar.set_description('TRAINING')\n",
    "                for X, T in in_bar:\n",
    "                    metrics = model.train_step(X, T)\n",
    "                    with writer_train.as_default():\n",
    "                        for metric in model.metrics:\n",
    "                            tf.summary.scalar(metric.name, metric.result(), step=epoch)\n",
    "                    in_bar.set_postfix({key: value.numpy() for key, value in metrics.items()})\n",
    "                    model.reset_metrics()\n",
    "            with tqdm(test, leave=False) as in_bar:\n",
    "                out_bar.set_description('TESTING')\n",
    "                for X, T in in_bar:\n",
    "                    metrics = model.test_step(X, T)\n",
    "                    with writer_val.as_default():\n",
    "                        for metric in model.metrics:\n",
    "                            tf.summary.scalar(metric.name, metric.result(), step=epoch)\n",
    "                    in_bar.set_postfix({key: value.numpy() for key, value in metrics.items()})\n",
    "                    model.reset_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d85e810",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb1d9df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training(epochs=1000, model=model, train=train, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8371f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('mnist_vanilla_v1', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823d5dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, T = batch = next(iter(test.batch(200)))\n",
    "Y_logits = model(X)\n",
    "Y = tf.nn.softmax(Y_logits)\n",
    "print(f\"{round(np.mean(np.argmax(Y, axis=1) == np.argmax(T, axis=1)) * 100, 1)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b107c2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                            | 0/12 [00:00<?, ?it/s]\n",
      "  0%|                                                                            | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████▊           | 10/12 [00:00<00:00, 98.79it/s]\u001b[A\n",
      "  8%|█████▋                                                              | 1/12 [00:00<00:02,  4.29it/s]\u001b[A\n",
      "  0%|                                                                            | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████▊           | 10/12 [00:00<00:00, 98.64it/s]\u001b[A\n",
      " 17%|███████████▎                                                        | 2/12 [00:00<00:02,  4.28it/s]\u001b[A\n",
      "  0%|                                                                            | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████▊           | 10/12 [00:00<00:00, 98.92it/s]\u001b[A\n",
      " 25%|█████████████████                                                   | 3/12 [00:00<00:02,  4.26it/s]\u001b[A\n",
      "  0%|                                                                            | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████▊           | 10/12 [00:00<00:00, 98.77it/s]\u001b[A\n",
      " 33%|██████████████████████▋                                             | 4/12 [00:00<00:01,  4.24it/s]\u001b[A\n",
      "  0%|                                                                            | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████▊           | 10/12 [00:00<00:00, 98.66it/s]\u001b[A\n",
      " 42%|████████████████████████████▎                                       | 5/12 [00:01<00:01,  4.23it/s]\u001b[A\n",
      "  0%|                                                                            | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████▊           | 10/12 [00:00<00:00, 98.77it/s]\u001b[A\n",
      " 50%|██████████████████████████████████                                  | 6/12 [00:01<00:01,  4.23it/s]\u001b[A\n",
      "  0%|                                                                            | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████▊           | 10/12 [00:00<00:00, 98.67it/s]\u001b[A\n",
      " 58%|███████████████████████████████████████▋                            | 7/12 [00:01<00:01,  4.24it/s]\u001b[A\n",
      "  0%|                                                                            | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████▊           | 10/12 [00:00<00:00, 98.72it/s]\u001b[A\n",
      " 67%|█████████████████████████████████████████████▎                      | 8/12 [00:01<00:00,  4.23it/s]\u001b[A\n",
      "  0%|                                                                            | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████▊           | 10/12 [00:00<00:00, 98.98it/s]\u001b[A\n",
      " 75%|███████████████████████████████████████████████████                 | 9/12 [00:02<00:00,  4.26it/s]\u001b[A\n",
      "  0%|                                                                            | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████▊           | 10/12 [00:00<00:00, 98.87it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████▊           | 10/12 [00:02<00:00,  4.27it/s]\u001b[A\n",
      "  0%|                                                                            | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████▊           | 10/12 [00:00<00:00, 98.72it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████████████████████████████▍     | 11/12 [00:02<00:00,  4.27it/s]\u001b[A\n",
      "  0%|                                                                            | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████▊           | 10/12 [00:00<00:00, 98.82it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  4.27it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm#\n",
    "#from tqdm.notebook import tqdm\n",
    "from time import sleep\n",
    "\n",
    "for _ in tqdm(range(12), leave=True):\n",
    "    sleep(0.1)\n",
    "    for _ in tqdm(range(12), leave=False):\n",
    "        sleep(0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
